{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project\n",
    "\n",
    "\n",
    "For your final project, you will build a classifer for\n",
    "the **Backorder Prediction** dataset by following our\n",
    "operationalized machine learning pipeline.\n",
    "\n",
    "![AppliedML_Workflow IMAGE MISSING](../images/AppliedML_Workflow.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "## Data\n",
    "\n",
    "Details of the dataset are located here:\n",
    "\n",
    "Dataset (originally posted on Kaggle): https://www.kaggle.com/tiredgeek/predict-bo-trial\n",
    "\n",
    "The files are accessible in the JupyterHub environment:\n",
    " * `/dsa/data/all_datasets/back_order/Kaggle_Training_Dataset_v2.csv`\n",
    " * `/dsa/data/all_datasets/back_order/Kaggle_Test_Dataset_v2.csv`\n",
    "\n",
    "The data is used to predict of product when on Back Order.\n",
    " \n",
    "**NOTE:** The training data file is 117MB.  \n",
    "You can easily lock up a notebook with bad coding practices.  \n",
    "Please save you project early, and often, and use `git commits` to checkpoint your process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration, Training, and Validation\n",
    "\n",
    "You will examine the _training_ dataset and perform \n",
    " * **data preparation and exploratory data analysis**, \n",
    " * **anomaly detection / removal**,\n",
    " * **dimensionality reduction** and then\n",
    " * **train and validate 3 different models**.\n",
    "\n",
    "Of the 3 different models, you are free to pick any estimator from scikit-learn \n",
    "or models we have so far covered using TensorFlow.\n",
    "\n",
    "### Validation Assessment\n",
    "\n",
    "Your first, intermediate, result will be an **assessment** of the models' performance.\n",
    "This assessement should be grounded within a 10-fold cross-validation methodology.\n",
    "\n",
    "This should include the confusion matrix and F-score for each classifier.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Testing\n",
    "\n",
    "Once you have chosen your final model, you will need to re-train it using all the training data.\n",
    "\n",
    "\n",
    "--- \n",
    "##  Overview / Roadmap\n",
    "\n",
    "**General steps**:\n",
    "\n",
    "* Dataset carpentry & Exploratory Data Analysis\n",
    "  * Develop functions to perform the necessary steps, you will have to carpentry the Training and the Testing data.\n",
    "* Create 3 pipelines, each does:\n",
    "    * Anomaly detection\n",
    "    * Dimensionality reduction\n",
    "    * Model training/validation\n",
    "* Train chosen model full training data\n",
    "* Evaluate model against testing\n",
    "* Write a summary of your processing and an analysis of the model performance\n",
    "\n",
    "\n",
    "#### <span style=\"background:yellow\">Note:</span> The use of sklearn Pipelines and FeatureUnion is optional.   \n",
    "However, your three models should follow a readable path from data to cross-validation statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os, sys\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset\n",
    "\n",
    "**Description**\n",
    "~~~\n",
    "sku - Random ID for the product\n",
    "national_inv - Current inventory level for the part\n",
    "lead_time - Transit time for product (if available)\n",
    "in_transit_qty - Amount of product in transit from source\n",
    "forecast_3_month - Forecast sales for the next 3 months\n",
    "forecast_6_month - Forecast sales for the next 6 months\n",
    "forecast_9_month - Forecast sales for the next 9 months\n",
    "sales_1_month - Sales quantity for the prior 1 month time period\n",
    "sales_3_month - Sales quantity for the prior 3 month time period\n",
    "sales_6_month - Sales quantity for the prior 6 month time period\n",
    "sales_9_month - Sales quantity for the prior 9 month time period\n",
    "min_bank - Minimum recommend amount to stock\n",
    "potential_issue - Source issue for part identified\n",
    "pieces_past_due - Parts overdue from source\n",
    "perf_6_month_avg - Source performance for prior 6 month period\n",
    "perf_12_month_avg - Source performance for prior 12 month period\n",
    "local_bo_qty - Amount of stock orders overdue\n",
    "deck_risk - Part risk flag\n",
    "oe_constraint - Part risk flag\n",
    "ppap_risk - Part risk flag\n",
    "stop_auto_buy - Part risk flag\n",
    "rev_stop - Part risk flag\n",
    "went_on_backorder - Product actually went on backorder. **This is the target value.**\n",
    "~~~\n",
    "\n",
    "**Note**: This is a real-world dataset without any processing.  \n",
    "There will also be warnings due to fact that the 1st column is mixing integer and string values.  \n",
    "The last column is what we are trying to predict."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "In an attempt to get a better understanding of the dataset it was realized that the dataset was no longer available from its source. However, several other sources of information on the dataset were discovered through a websearch. Gleaning insights from these sources, a different workflow for exploratory analysis than what was originally laid out in this notebook was developed and deployed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.4/site-packages/IPython/core/interactiveshell.py:2728: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>national_inv</th>\n",
       "      <th>lead_time</th>\n",
       "      <th>in_transit_qty</th>\n",
       "      <th>forecast_3_month</th>\n",
       "      <th>forecast_6_month</th>\n",
       "      <th>forecast_9_month</th>\n",
       "      <th>sales_1_month</th>\n",
       "      <th>sales_3_month</th>\n",
       "      <th>sales_6_month</th>\n",
       "      <th>sales_9_month</th>\n",
       "      <th>min_bank</th>\n",
       "      <th>pieces_past_due</th>\n",
       "      <th>perf_6_month_avg</th>\n",
       "      <th>perf_12_month_avg</th>\n",
       "      <th>local_bo_qty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.687860e+06</td>\n",
       "      <td>1.586967e+06</td>\n",
       "      <td>1.687860e+06</td>\n",
       "      <td>1.687860e+06</td>\n",
       "      <td>1.687860e+06</td>\n",
       "      <td>1.687860e+06</td>\n",
       "      <td>1.687860e+06</td>\n",
       "      <td>1.687860e+06</td>\n",
       "      <td>1.687860e+06</td>\n",
       "      <td>1.687860e+06</td>\n",
       "      <td>1.687860e+06</td>\n",
       "      <td>1.687860e+06</td>\n",
       "      <td>1.558382e+06</td>\n",
       "      <td>1.565810e+06</td>\n",
       "      <td>1.687860e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.961118e+02</td>\n",
       "      <td>7.872267e+00</td>\n",
       "      <td>4.405202e+01</td>\n",
       "      <td>1.781193e+02</td>\n",
       "      <td>3.449867e+02</td>\n",
       "      <td>5.063644e+02</td>\n",
       "      <td>5.592607e+01</td>\n",
       "      <td>1.750259e+02</td>\n",
       "      <td>3.417288e+02</td>\n",
       "      <td>5.252697e+02</td>\n",
       "      <td>5.277230e+01</td>\n",
       "      <td>2.043724e+00</td>\n",
       "      <td>7.823812e-01</td>\n",
       "      <td>7.769763e-01</td>\n",
       "      <td>6.264507e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.961523e+04</td>\n",
       "      <td>7.056024e+00</td>\n",
       "      <td>1.342742e+03</td>\n",
       "      <td>5.026553e+03</td>\n",
       "      <td>9.795152e+03</td>\n",
       "      <td>1.437892e+04</td>\n",
       "      <td>1.928196e+03</td>\n",
       "      <td>5.192378e+03</td>\n",
       "      <td>9.613167e+03</td>\n",
       "      <td>1.483861e+04</td>\n",
       "      <td>1.254983e+03</td>\n",
       "      <td>2.360165e+02</td>\n",
       "      <td>2.370141e-01</td>\n",
       "      <td>2.304902e-01</td>\n",
       "      <td>3.372224e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.725600e+04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7.000000e-01</td>\n",
       "      <td>6.900000e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.500000e+01</td>\n",
       "      <td>8.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8.500000e-01</td>\n",
       "      <td>8.300000e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.000000e+01</td>\n",
       "      <td>9.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>1.200000e+01</td>\n",
       "      <td>2.000000e+01</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>1.500000e+01</td>\n",
       "      <td>3.100000e+01</td>\n",
       "      <td>4.700000e+01</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>9.700000e-01</td>\n",
       "      <td>9.600000e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.233440e+07</td>\n",
       "      <td>5.200000e+01</td>\n",
       "      <td>4.894080e+05</td>\n",
       "      <td>1.427612e+06</td>\n",
       "      <td>2.461360e+06</td>\n",
       "      <td>3.777304e+06</td>\n",
       "      <td>7.417740e+05</td>\n",
       "      <td>1.105478e+06</td>\n",
       "      <td>2.146625e+06</td>\n",
       "      <td>3.205172e+06</td>\n",
       "      <td>3.133190e+05</td>\n",
       "      <td>1.464960e+05</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.253000e+04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       national_inv     lead_time  in_transit_qty  forecast_3_month  \\\n",
       "count  1.687860e+06  1.586967e+06    1.687860e+06      1.687860e+06   \n",
       "mean   4.961118e+02  7.872267e+00    4.405202e+01      1.781193e+02   \n",
       "std    2.961523e+04  7.056024e+00    1.342742e+03      5.026553e+03   \n",
       "min   -2.725600e+04  0.000000e+00    0.000000e+00      0.000000e+00   \n",
       "25%    4.000000e+00  4.000000e+00    0.000000e+00      0.000000e+00   \n",
       "50%    1.500000e+01  8.000000e+00    0.000000e+00      0.000000e+00   \n",
       "75%    8.000000e+01  9.000000e+00    0.000000e+00      4.000000e+00   \n",
       "max    1.233440e+07  5.200000e+01    4.894080e+05      1.427612e+06   \n",
       "\n",
       "       forecast_6_month  forecast_9_month  sales_1_month  sales_3_month  \\\n",
       "count      1.687860e+06      1.687860e+06   1.687860e+06   1.687860e+06   \n",
       "mean       3.449867e+02      5.063644e+02   5.592607e+01   1.750259e+02   \n",
       "std        9.795152e+03      1.437892e+04   1.928196e+03   5.192378e+03   \n",
       "min        0.000000e+00      0.000000e+00   0.000000e+00   0.000000e+00   \n",
       "25%        0.000000e+00      0.000000e+00   0.000000e+00   0.000000e+00   \n",
       "50%        0.000000e+00      0.000000e+00   0.000000e+00   1.000000e+00   \n",
       "75%        1.200000e+01      2.000000e+01   4.000000e+00   1.500000e+01   \n",
       "max        2.461360e+06      3.777304e+06   7.417740e+05   1.105478e+06   \n",
       "\n",
       "       sales_6_month  sales_9_month      min_bank  pieces_past_due  \\\n",
       "count   1.687860e+06   1.687860e+06  1.687860e+06     1.687860e+06   \n",
       "mean    3.417288e+02   5.252697e+02  5.277230e+01     2.043724e+00   \n",
       "std     9.613167e+03   1.483861e+04  1.254983e+03     2.360165e+02   \n",
       "min     0.000000e+00   0.000000e+00  0.000000e+00     0.000000e+00   \n",
       "25%     0.000000e+00   0.000000e+00  0.000000e+00     0.000000e+00   \n",
       "50%     2.000000e+00   4.000000e+00  0.000000e+00     0.000000e+00   \n",
       "75%     3.100000e+01   4.700000e+01  3.000000e+00     0.000000e+00   \n",
       "max     2.146625e+06   3.205172e+06  3.133190e+05     1.464960e+05   \n",
       "\n",
       "       perf_6_month_avg  perf_12_month_avg  local_bo_qty  \n",
       "count      1.558382e+06       1.565810e+06  1.687860e+06  \n",
       "mean       7.823812e-01       7.769763e-01  6.264507e-01  \n",
       "std        2.370141e-01       2.304902e-01  3.372224e+01  \n",
       "min        0.000000e+00       0.000000e+00  0.000000e+00  \n",
       "25%        7.000000e-01       6.900000e-01  0.000000e+00  \n",
       "50%        8.500000e-01       8.300000e-01  0.000000e+00  \n",
       "75%        9.700000e-01       9.600000e-01  0.000000e+00  \n",
       "max        1.000000e+00       1.000000e+00  1.253000e+04  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataset location\n",
    "DATASET = '/dsa/data/all_datasets/back_order/Kaggle_Training_Dataset_v2.csv'\n",
    "assert os.path.exists(DATASET)\n",
    "\n",
    "# Shuffling the dataset has been moved to later in the workflow to simplify exploratory analysis. Additional web sources \n",
    "# verified that the -99 values found in perf_6_month_avg and perf_12_month_avg are meant to be placeholders for NaN values. \n",
    "# The negative values in national_inv are described as valid values.\n",
    "\n",
    "# We will replace the -99 values with NaNs while pushing the data into a Pandas dataframe.\n",
    "\n",
    "na_other = {'perf_6_month_avg':-99, 'perf_12_month_avg':-99}\n",
    "\n",
    "dataset = pd.read_csv(DATASET, na_values=na_other)\n",
    "dataset.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sku</th>\n",
       "      <th>potential_issue</th>\n",
       "      <th>deck_risk</th>\n",
       "      <th>oe_constraint</th>\n",
       "      <th>ppap_risk</th>\n",
       "      <th>stop_auto_buy</th>\n",
       "      <th>rev_stop</th>\n",
       "      <th>went_on_backorder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1687861</td>\n",
       "      <td>1687860</td>\n",
       "      <td>1687860</td>\n",
       "      <td>1687860</td>\n",
       "      <td>1687860</td>\n",
       "      <td>1687860</td>\n",
       "      <td>1687860</td>\n",
       "      <td>1687860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1687861</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>1579532</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>1686953</td>\n",
       "      <td>1300377</td>\n",
       "      <td>1687615</td>\n",
       "      <td>1484026</td>\n",
       "      <td>1626774</td>\n",
       "      <td>1687129</td>\n",
       "      <td>1676567</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            sku potential_issue deck_risk oe_constraint ppap_risk  \\\n",
       "count   1687861         1687860   1687860       1687860   1687860   \n",
       "unique  1687861               2         2             2         2   \n",
       "top     1579532              No        No            No        No   \n",
       "freq          1         1686953   1300377       1687615   1484026   \n",
       "\n",
       "       stop_auto_buy rev_stop went_on_backorder  \n",
       "count        1687860  1687860           1687860  \n",
       "unique             2        2                 2  \n",
       "top              Yes       No                No  \n",
       "freq         1626774  1687129           1676567  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summarise the non-numerical data\n",
    "\n",
    "dataset.describe(include=['O'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sku</th>\n",
       "      <th>national_inv</th>\n",
       "      <th>lead_time</th>\n",
       "      <th>in_transit_qty</th>\n",
       "      <th>forecast_3_month</th>\n",
       "      <th>forecast_6_month</th>\n",
       "      <th>forecast_9_month</th>\n",
       "      <th>sales_1_month</th>\n",
       "      <th>sales_3_month</th>\n",
       "      <th>sales_6_month</th>\n",
       "      <th>...</th>\n",
       "      <th>pieces_past_due</th>\n",
       "      <th>perf_6_month_avg</th>\n",
       "      <th>perf_12_month_avg</th>\n",
       "      <th>local_bo_qty</th>\n",
       "      <th>deck_risk</th>\n",
       "      <th>oe_constraint</th>\n",
       "      <th>ppap_risk</th>\n",
       "      <th>stop_auto_buy</th>\n",
       "      <th>rev_stop</th>\n",
       "      <th>went_on_backorder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1026827</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1043384</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1043696</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1043852</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1044048</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1044198</td>\n",
       "      <td>13.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1044643</td>\n",
       "      <td>1095.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1045098</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1045815</td>\n",
       "      <td>140.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1045867</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sku  national_inv  lead_time  in_transit_qty  forecast_3_month  \\\n",
       "0  1026827           0.0        NaN             0.0               0.0   \n",
       "1  1043384           2.0        9.0             0.0               0.0   \n",
       "2  1043696           2.0        NaN             0.0               0.0   \n",
       "3  1043852           7.0        8.0             0.0               0.0   \n",
       "4  1044048           8.0        NaN             0.0               0.0   \n",
       "5  1044198          13.0        8.0             0.0               0.0   \n",
       "6  1044643        1095.0        NaN             0.0               0.0   \n",
       "7  1045098           6.0        2.0             0.0               0.0   \n",
       "8  1045815         140.0        NaN             0.0              15.0   \n",
       "9  1045867           4.0        8.0             0.0               0.0   \n",
       "\n",
       "   forecast_6_month  forecast_9_month  sales_1_month  sales_3_month  \\\n",
       "0               0.0               0.0            0.0            0.0   \n",
       "1               0.0               0.0            0.0            0.0   \n",
       "2               0.0               0.0            0.0            0.0   \n",
       "3               0.0               0.0            0.0            0.0   \n",
       "4               0.0               0.0            0.0            0.0   \n",
       "5               0.0               0.0            0.0            0.0   \n",
       "6               0.0               0.0            0.0            0.0   \n",
       "7               0.0               0.0            0.0            0.0   \n",
       "8             114.0             152.0            0.0            0.0   \n",
       "9               0.0               0.0            0.0            0.0   \n",
       "\n",
       "   sales_6_month        ...         pieces_past_due  perf_6_month_avg  \\\n",
       "0            0.0        ...                     0.0               NaN   \n",
       "1            0.0        ...                     0.0              0.99   \n",
       "2            0.0        ...                     0.0               NaN   \n",
       "3            0.0        ...                     0.0              0.10   \n",
       "4            0.0        ...                     0.0               NaN   \n",
       "5            0.0        ...                     0.0              0.82   \n",
       "6            0.0        ...                     0.0               NaN   \n",
       "7            0.0        ...                     0.0              0.00   \n",
       "8            0.0        ...                     0.0               NaN   \n",
       "9            0.0        ...                     0.0              0.82   \n",
       "\n",
       "  perf_12_month_avg  local_bo_qty  deck_risk  oe_constraint  ppap_risk  \\\n",
       "0               NaN           0.0         No             No         No   \n",
       "1              0.99           0.0         No             No         No   \n",
       "2               NaN           0.0        Yes             No         No   \n",
       "3              0.13           0.0         No             No         No   \n",
       "4               NaN           0.0        Yes             No         No   \n",
       "5              0.87           0.0         No             No         No   \n",
       "6               NaN           0.0        Yes             No         No   \n",
       "7              0.00           0.0        Yes             No        Yes   \n",
       "8               NaN           0.0         No             No         No   \n",
       "9              0.87           0.0         No             No         No   \n",
       "\n",
       "  stop_auto_buy rev_stop went_on_backorder  \n",
       "0           Yes       No                No  \n",
       "1           Yes       No                No  \n",
       "2           Yes       No                No  \n",
       "3           Yes       No                No  \n",
       "4           Yes       No                No  \n",
       "5           Yes       No                No  \n",
       "6           Yes       No                No  \n",
       "7           Yes       No                No  \n",
       "8           Yes       No                No  \n",
       "9           Yes       No                No  \n",
       "\n",
       "[10 rows x 23 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show top 10 rows\n",
    "\n",
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.4/site-packages/ipykernel_launcher.py:3: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sales_9_month</th>\n",
       "      <th>min_bank</th>\n",
       "      <th>potential_issue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sales_9_month  min_bank potential_issue\n",
       "0            0.0       0.0              No\n",
       "1            0.0       0.0              No\n",
       "2            0.0       0.0              No\n",
       "3            0.0       1.0              No\n",
       "4            4.0       2.0              No\n",
       "5            0.0       0.0              No\n",
       "6            0.0       4.0              No\n",
       "7            0.0       0.0              No\n",
       "8            0.0       0.0              No\n",
       "9            0.0       0.0              No"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show top 10 rows of columns that were cut out\n",
    "\n",
    "dataset.ix[0:9,'sales_9_month':'potential_issue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sku</th>\n",
       "      <th>national_inv</th>\n",
       "      <th>lead_time</th>\n",
       "      <th>in_transit_qty</th>\n",
       "      <th>forecast_3_month</th>\n",
       "      <th>forecast_6_month</th>\n",
       "      <th>forecast_9_month</th>\n",
       "      <th>sales_1_month</th>\n",
       "      <th>sales_3_month</th>\n",
       "      <th>sales_6_month</th>\n",
       "      <th>...</th>\n",
       "      <th>pieces_past_due</th>\n",
       "      <th>perf_6_month_avg</th>\n",
       "      <th>perf_12_month_avg</th>\n",
       "      <th>local_bo_qty</th>\n",
       "      <th>deck_risk</th>\n",
       "      <th>oe_constraint</th>\n",
       "      <th>ppap_risk</th>\n",
       "      <th>stop_auto_buy</th>\n",
       "      <th>rev_stop</th>\n",
       "      <th>went_on_backorder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1687851</th>\n",
       "      <td>1373539</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.10</td>\n",
       "      <td>42.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1687852</th>\n",
       "      <td>1478683</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>966.0</td>\n",
       "      <td>966.0</td>\n",
       "      <td>1116.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>512.0</td>\n",
       "      <td>1361.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.77</td>\n",
       "      <td>46.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1687853</th>\n",
       "      <td>1489920</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2071.0</td>\n",
       "      <td>3025.0</td>\n",
       "      <td>3412.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>764.0</td>\n",
       "      <td>764.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "      <td>4.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1687854</th>\n",
       "      <td>1392420</td>\n",
       "      <td>124.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>410.0</td>\n",
       "      <td>780.0</td>\n",
       "      <td>1240.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>464.0</td>\n",
       "      <td>849.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1687855</th>\n",
       "      <td>1407754</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.69</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1687856</th>\n",
       "      <td>1373987</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1687857</th>\n",
       "      <td>1524346</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.84</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1687858</th>\n",
       "      <td>1439563</td>\n",
       "      <td>62.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.84</td>\n",
       "      <td>6.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1687859</th>\n",
       "      <td>1502009</td>\n",
       "      <td>19.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.78</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1687860</th>\n",
       "      <td>(1687860 rows)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    sku  national_inv  lead_time  in_transit_qty  \\\n",
       "1687851         1373539          -6.0        9.0            36.0   \n",
       "1687852         1478683           2.0        8.0             0.0   \n",
       "1687853         1489920           0.0        2.0             0.0   \n",
       "1687854         1392420         124.0        8.0           140.0   \n",
       "1687855         1407754           0.0        2.0             0.0   \n",
       "1687856         1373987          -1.0        NaN             0.0   \n",
       "1687857         1524346          -1.0        9.0             0.0   \n",
       "1687858         1439563          62.0        9.0            16.0   \n",
       "1687859         1502009          19.0        4.0             0.0   \n",
       "1687860  (1687860 rows)           NaN        NaN             NaN   \n",
       "\n",
       "         forecast_3_month  forecast_6_month  forecast_9_month  sales_1_month  \\\n",
       "1687851             130.0             130.0             130.0            0.0   \n",
       "1687852             966.0             966.0            1116.0           47.0   \n",
       "1687853            2071.0            3025.0            3412.0            4.0   \n",
       "1687854             410.0             780.0            1240.0          128.0   \n",
       "1687855              10.0              10.0              10.0            0.0   \n",
       "1687856               5.0               7.0               9.0            1.0   \n",
       "1687857               7.0               9.0              11.0            0.0   \n",
       "1687858              39.0              87.0             126.0           35.0   \n",
       "1687859               0.0               0.0               0.0            2.0   \n",
       "1687860               NaN               NaN               NaN            NaN   \n",
       "\n",
       "         sales_3_month  sales_6_month        ...         pieces_past_due  \\\n",
       "1687851            0.0           54.0        ...                     0.0   \n",
       "1687852          512.0         1361.0        ...                     0.0   \n",
       "1687853          764.0          764.0        ...                     0.0   \n",
       "1687854          464.0          849.0        ...                     0.0   \n",
       "1687855            5.0            7.0        ...                     0.0   \n",
       "1687856            3.0            3.0        ...                     0.0   \n",
       "1687857            8.0           11.0        ...                     0.0   \n",
       "1687858           63.0          153.0        ...                     0.0   \n",
       "1687859            7.0           12.0        ...                     0.0   \n",
       "1687860            NaN            NaN        ...                     NaN   \n",
       "\n",
       "         perf_6_month_avg perf_12_month_avg  local_bo_qty  deck_risk  \\\n",
       "1687851              0.03              0.10          42.0         No   \n",
       "1687852              0.84              0.77          46.0         No   \n",
       "1687853              0.98              0.99           4.0         No   \n",
       "1687854              0.85              0.90           1.0         No   \n",
       "1687855              0.69              0.69           5.0        Yes   \n",
       "1687856               NaN               NaN           1.0         No   \n",
       "1687857              0.86              0.84           1.0        Yes   \n",
       "1687858              0.86              0.84           6.0         No   \n",
       "1687859              0.73              0.78           1.0         No   \n",
       "1687860               NaN               NaN           NaN        NaN   \n",
       "\n",
       "         oe_constraint  ppap_risk stop_auto_buy rev_stop went_on_backorder  \n",
       "1687851             No         No           Yes       No                No  \n",
       "1687852             No         No           Yes       No                No  \n",
       "1687853             No         No            No       No               Yes  \n",
       "1687854             No         No           Yes       No                No  \n",
       "1687855             No         No           Yes       No                No  \n",
       "1687856             No         No           Yes       No                No  \n",
       "1687857             No         No            No       No               Yes  \n",
       "1687858             No         No           Yes       No                No  \n",
       "1687859             No         No           Yes       No                No  \n",
       "1687860            NaN        NaN           NaN      NaN               NaN  \n",
       "\n",
       "[10 rows x 23 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show bottom 10 rows\n",
    "\n",
    "dataset.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing\n",
    "\n",
    "In this section, goal is to figure out:\n",
    "\n",
    "* which columns we can use directly,  \n",
    "* which columns are usable after some processing,  \n",
    "* and which columns are not processable or obviously irrelevant (like product id) that we will discard.\n",
    "\n",
    "Then process and prepare this dataset for creating a predictive model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1687861 entries, 0 to 1687860\n",
      "Data columns (total 23 columns):\n",
      "sku                  1687861 non-null object\n",
      "national_inv         1687860 non-null float64\n",
      "lead_time            1586967 non-null float64\n",
      "in_transit_qty       1687860 non-null float64\n",
      "forecast_3_month     1687860 non-null float64\n",
      "forecast_6_month     1687860 non-null float64\n",
      "forecast_9_month     1687860 non-null float64\n",
      "sales_1_month        1687860 non-null float64\n",
      "sales_3_month        1687860 non-null float64\n",
      "sales_6_month        1687860 non-null float64\n",
      "sales_9_month        1687860 non-null float64\n",
      "min_bank             1687860 non-null float64\n",
      "potential_issue      1687860 non-null object\n",
      "pieces_past_due      1687860 non-null float64\n",
      "perf_6_month_avg     1558382 non-null float64\n",
      "perf_12_month_avg    1565810 non-null float64\n",
      "local_bo_qty         1687860 non-null float64\n",
      "deck_risk            1687860 non-null object\n",
      "oe_constraint        1687860 non-null object\n",
      "ppap_risk            1687860 non-null object\n",
      "stop_auto_buy        1687860 non-null object\n",
      "rev_stop             1687860 non-null object\n",
      "went_on_backorder    1687860 non-null object\n",
      "dtypes: float64(15), object(8)\n",
      "memory usage: 296.2+ MB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take samples and examine the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sku</th>\n",
       "      <th>national_inv</th>\n",
       "      <th>lead_time</th>\n",
       "      <th>in_transit_qty</th>\n",
       "      <th>forecast_3_month</th>\n",
       "      <th>forecast_6_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1026827</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1043384</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1043696</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sku  national_inv  lead_time  in_transit_qty  forecast_3_month  \\\n",
       "0  1026827           0.0        NaN             0.0               0.0   \n",
       "1  1043384           2.0        9.0             0.0               0.0   \n",
       "2  1043696           2.0        NaN             0.0               0.0   \n",
       "\n",
       "   forecast_6_month  \n",
       "0               0.0  \n",
       "1               0.0  \n",
       "2               0.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.iloc[:3,:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>forecast_9_month</th>\n",
       "      <th>sales_1_month</th>\n",
       "      <th>sales_3_month</th>\n",
       "      <th>sales_6_month</th>\n",
       "      <th>sales_9_month</th>\n",
       "      <th>min_bank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   forecast_9_month  sales_1_month  sales_3_month  sales_6_month  \\\n",
       "0               0.0            0.0            0.0            0.0   \n",
       "1               0.0            0.0            0.0            0.0   \n",
       "2               0.0            0.0            0.0            0.0   \n",
       "\n",
       "   sales_9_month  min_bank  \n",
       "0            0.0       0.0  \n",
       "1            0.0       0.0  \n",
       "2            0.0       0.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.iloc[:3,6:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>potential_issue</th>\n",
       "      <th>pieces_past_due</th>\n",
       "      <th>perf_6_month_avg</th>\n",
       "      <th>perf_12_month_avg</th>\n",
       "      <th>local_bo_qty</th>\n",
       "      <th>deck_risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  potential_issue  pieces_past_due  perf_6_month_avg  perf_12_month_avg  \\\n",
       "0              No              0.0               NaN                NaN   \n",
       "1              No              0.0              0.99               0.99   \n",
       "2              No              0.0               NaN                NaN   \n",
       "\n",
       "   local_bo_qty deck_risk  \n",
       "0           0.0        No  \n",
       "1           0.0        No  \n",
       "2           0.0       Yes  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.iloc[:3,12:18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>oe_constraint</th>\n",
       "      <th>ppap_risk</th>\n",
       "      <th>stop_auto_buy</th>\n",
       "      <th>rev_stop</th>\n",
       "      <th>went_on_backorder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  oe_constraint ppap_risk stop_auto_buy rev_stop went_on_backorder\n",
       "0            No        No           Yes       No                No\n",
       "1            No        No           Yes       No                No\n",
       "2            No        No           Yes       No                No"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.iloc[:3,18:24]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop columns that are obviously irrelevant or not processable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add code below this comment  (Question #E8001)\n",
    "# ----------------------------------\n",
    "\n",
    "dataset = dataset.drop(['sku'], axis = 1)\n",
    "\n",
    "# We will also drop the last row consisting of all NaN values\n",
    "\n",
    "dataset = dataset[:-1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find unique values of string columns\n",
    "\n",
    "Now try to make sure that these Yes/No columns really only contains Yes or No.  \n",
    "If that's true, proceed to convert them into binaries (0s and 1s).\n",
    "\n",
    "**Tip**: use [unique()](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.unique.html) function of pandas Series.\n",
    "\n",
    "Example\n",
    "\n",
    "~~~python\n",
    "print('went_on_backorder', dataset['went_on_backorder'].unique())\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['potential_issue', 'deck_risk', 'oe_constraint', 'ppap_risk', 'stop_auto_buy', 'rev_stop', 'went_on_backorder']\n",
      "potential_issue ['No' 'Yes']\n",
      "deck_risk ['No' 'Yes']\n",
      "oe_constraint ['No' 'Yes']\n",
      "ppap_risk ['No' 'Yes']\n",
      "stop_auto_buy ['Yes' 'No']\n",
      "rev_stop ['No' 'Yes']\n",
      "went_on_backorder ['No' 'Yes']\n"
     ]
    }
   ],
   "source": [
    "# All the column names of these yes/no columns\n",
    "yes_no_columns = list(filter(lambda i: dataset[i].dtype!=np.float64, dataset.columns))\n",
    "print(yes_no_columns)\n",
    "\n",
    "# Add code below this comment  (Question #E8002)\n",
    "# ----------------------------------\n",
    "print('potential_issue', dataset['potential_issue'].unique())\n",
    "print('deck_risk', dataset['deck_risk'].unique())\n",
    "print('oe_constraint', dataset['oe_constraint'].unique())\n",
    "print('ppap_risk', dataset['ppap_risk'].unique())\n",
    "print('stop_auto_buy', dataset['stop_auto_buy'].unique())\n",
    "print('rev_stop', dataset['rev_stop'].unique())\n",
    "print('went_on_backorder', dataset['went_on_backorder'].unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may see **nan** also as possible values representing missing values in the dataset.\n",
    "\n",
    "We fill them using most popular values, the [Mode](https://en.wikipedia.org/wiki/Mode_%28statistics%29) in Stats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This step is not necessary because apparently the only row with NaNs for the string columns was that last row\n",
    "\n",
    "# for column_name in yes_no_columns:\n",
    "    # mode = dataset[column_name].apply(str).mode()[0]\n",
    "    # print('Filling missing values of {} with {}'.format(column_name, mode))\n",
    "    # dataset[column_name].fillna(mode, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "national_inv         False\n",
       "lead_time             True\n",
       "in_transit_qty       False\n",
       "forecast_3_month     False\n",
       "forecast_6_month     False\n",
       "forecast_9_month     False\n",
       "sales_1_month        False\n",
       "sales_3_month        False\n",
       "sales_6_month        False\n",
       "sales_9_month        False\n",
       "min_bank             False\n",
       "potential_issue      False\n",
       "pieces_past_due      False\n",
       "perf_6_month_avg      True\n",
       "perf_12_month_avg     True\n",
       "local_bo_qty         False\n",
       "deck_risk            False\n",
       "oe_constraint        False\n",
       "ppap_risk            False\n",
       "stop_auto_buy        False\n",
       "rev_stop             False\n",
       "went_on_backorder    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets see where our remaining NaNs are\n",
    "\n",
    "dataset.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "129478"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets see just how many rows include NaNs\n",
    "\n",
    "dataset.shape[0] - dataset.dropna().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.671133861813184"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If we were to remove these rows from the dataset how much data would we lose?\n",
    "\n",
    "129478/1687860*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 7% is less than 10%. I believe it is reasonable to drop these observations without affecting the results of our modeling\n",
    "\n",
    "dataset = dataset.dropna()\n",
    "dataset.isnull().any().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11293"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Referring back to when we described the went_on_backorder variable, we see that there were 1676567 \"No\" values. How many\n",
    "# yes values were there?\n",
    "\n",
    "1687860-1676567"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>potential_issue</th>\n",
       "      <th>deck_risk</th>\n",
       "      <th>oe_constraint</th>\n",
       "      <th>ppap_risk</th>\n",
       "      <th>stop_auto_buy</th>\n",
       "      <th>rev_stop</th>\n",
       "      <th>went_on_backorder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1558382</td>\n",
       "      <td>1558382</td>\n",
       "      <td>1558382</td>\n",
       "      <td>1558382</td>\n",
       "      <td>1558382</td>\n",
       "      <td>1558382</td>\n",
       "      <td>1558382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1557502</td>\n",
       "      <td>1244372</td>\n",
       "      <td>1558137</td>\n",
       "      <td>1375836</td>\n",
       "      <td>1522966</td>\n",
       "      <td>1558013</td>\n",
       "      <td>1547519</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       potential_issue deck_risk oe_constraint ppap_risk stop_auto_buy  \\\n",
       "count          1558382   1558382       1558382   1558382       1558382   \n",
       "unique               2         2             2         2             2   \n",
       "top                 No        No            No        No           Yes   \n",
       "freq           1557502   1244372       1558137   1375836       1522966   \n",
       "\n",
       "       rev_stop went_on_backorder  \n",
       "count   1558382           1558382  \n",
       "unique        2                 2  \n",
       "top          No                No  \n",
       "freq    1558013           1547519  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets look at these figures now that we removed observations that included NaNs\n",
    "\n",
    "dataset.describe(include=['O'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "129048"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We now have 1547519 \"No\" values, so how many did we lose?\n",
    "\n",
    "1676567-1547519"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10863"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Okay. So how many \"Yes\" values do we have now?\n",
    "\n",
    "1558382-1547519"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "430"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Which means we lost:\n",
    "\n",
    "11293-10863"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "These losses appear to be proportionally acceptable. Furthermore we should take note that our tagert variable values are very imbalanced. We'll come back to this later on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert yes/no columns into binary (0s and 1s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add code below this comment  (Question #E8003)\n",
    "# ----------------------------------\n",
    "\n",
    "for column_name in yes_no_columns:\n",
    "    dataset[column_name] = dataset[column_name].apply(['No', 'Yes'].index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now all columns should be either int64 or float64."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1558382 entries, 1 to 1687859\n",
      "Data columns (total 22 columns):\n",
      "national_inv         1558382 non-null float64\n",
      "lead_time            1558382 non-null float64\n",
      "in_transit_qty       1558382 non-null float64\n",
      "forecast_3_month     1558382 non-null float64\n",
      "forecast_6_month     1558382 non-null float64\n",
      "forecast_9_month     1558382 non-null float64\n",
      "sales_1_month        1558382 non-null float64\n",
      "sales_3_month        1558382 non-null float64\n",
      "sales_6_month        1558382 non-null float64\n",
      "sales_9_month        1558382 non-null float64\n",
      "min_bank             1558382 non-null float64\n",
      "potential_issue      1558382 non-null int64\n",
      "pieces_past_due      1558382 non-null float64\n",
      "perf_6_month_avg     1558382 non-null float64\n",
      "perf_12_month_avg    1558382 non-null float64\n",
      "local_bo_qty         1558382 non-null float64\n",
      "deck_risk            1558382 non-null int64\n",
      "oe_constraint        1558382 non-null int64\n",
      "ppap_risk            1558382 non-null int64\n",
      "stop_auto_buy        1558382 non-null int64\n",
      "rev_stop             1558382 non-null int64\n",
      "went_on_backorder    1558382 non-null int64\n",
      "dtypes: float64(15), int64(7)\n",
      "memory usage: 273.5 MB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ok now let's shuffle the dataset\n",
    "\n",
    "dataset = dataset.sample(frac = 1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    10863\n",
       "0    10863\n",
       "Name: went_on_backorder, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As we mentioned our target variable classes are very imbaolanced. To compensate for this, we will downsample the data so there\n",
    "# are as many \"No\"s as \"Yes\"s for went_on_backorder in our training set. Additionally, the smaller sample set will allow us to \n",
    "# train our models more quickly.\n",
    "\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Separate majority and minority values\n",
    "dataset_majority = dataset[dataset.went_on_backorder==0]\n",
    "dataset_minority = dataset[dataset.went_on_backorder==1]\n",
    "\n",
    "# Downsample majority values\n",
    "dataset_majority_downsampled = resample(dataset_majority, \n",
    "                                 replace=False, # sample without replacement\n",
    "                                 n_samples=(dataset_minority.went_on_backorder).count(),     # to match minority class\n",
    "                                 random_state=123) # reproducible results\n",
    "\n",
    "# Combine minority value with downsampled majority value\n",
    "dataset_downsampled = pd.concat([dataset_majority_downsampled, dataset_minority])\n",
    "\n",
    "# Check that we did this right: show value counts (they should be equal)\n",
    "dataset_downsampled.went_on_backorder.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# And now let's split into train and test subsets\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "X = dataset_downsampled.iloc[:, :-1]\n",
    "y = dataset_downsampled['went_on_backorder']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline\n",
    "\n",
    "In this section, design an operationalized machine learning pipeline, which includes:\n",
    "\n",
    "* Anomaly detection\n",
    "* Dimensionality Reduction\n",
    "* Train a model\n",
    "\n",
    "You can add more notebook cells or import any Python modules as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.ensemble import IsolationForest, RandomForestClassifier\n",
    "\n",
    "from sklearn.decomposition import PCA, FactorAnalysis, NMF\n",
    "from sklearn.preprocessing import StandardScaler, scale, Normalizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2, f_classif, mutual_info_classif\n",
    "\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report, accuracy_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your 1st pipeline \n",
    "  * Anomaly detection\n",
    "  * Dimensionality reduction\n",
    "  * Model training/validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add code below this comment  (Question #E8004)\n",
    "# ----------------------------------\n",
    "\n",
    "# For our first pipeline we will use a Gaussian Naive Bayes model.\n",
    "# We will start with anomolay detection/removal using an Elliptic Envelope.\n",
    "\n",
    "envelope = EllipticEnvelope().fit(X_train)\n",
    "\n",
    "outliers = envelope.predict(X_train)==-1\n",
    "X_train_clean = X_train[~outliers]\n",
    "y_train_clean = y_train[~outliers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('scl', StandardScaler(copy=True, with_mean=True, with_std=True)), ('selector', SelectKBest(k=6, score_func=<function mutual_info_classif at 0x7f1367b05598>)), ('clf', GaussianNB(priors=None))])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we build the pipeline. We will scale the data using StandarScaler() and reduce dimensions by feature selection via \n",
    "# SelectKBest and mutual_info_classif. After experimentation, 6 features were determined to produce the best results.\n",
    "\n",
    "pipe_nb = Pipeline([('scl', StandardScaler()),\n",
    "                    ('selector', SelectKBest(mutual_info_classif, k=6)),\n",
    "                    ('clf', GaussianNB())])\n",
    "\n",
    "pipe_nb.fit(X_train_clean, y_train_clean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.50995406,  0.51687117,  0.53527607,  0.51533742,  0.50766871,\n",
       "        0.50766871,  0.51687117,  0.50998464,  0.51459293,  0.50691244])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_nb = cross_val_score(pipe_nb, X_test, y_test, cv=10)\n",
    "scores_nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.51411373250876813"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_nb.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        pred:0  pred:1\n",
      "true:0    2820     427\n",
      "true:1    1732    1539\n"
     ]
    }
   ],
   "source": [
    "predictions_nb = pipe_nb.predict(X_test)\n",
    "\n",
    "unique_label = np.unique(y_test)\n",
    "print(pd.DataFrame(confusion_matrix(y_test, predictions_nb, labels=unique_label), \n",
    "                   index=['true:{:}'.format(x) for x in unique_label], \n",
    "                   columns=['pred:{:}'.format(x) for x in unique_label]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.87      0.72      3247\n",
      "          1       0.78      0.47      0.59      3271\n",
      "\n",
      "avg / total       0.70      0.67      0.66      6518\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predictions_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.66876342436330161"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, predictions_nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your 2nd pipeline\n",
    "  * Anomaly detection\n",
    "  * Dimensionality reduction\n",
    "  * Model training/validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add code below this comment  (Question #E8005)\n",
    "# ----------------------------------\n",
    "\n",
    "# For our second pipeline we will use a Logistic Regression model.\n",
    "# We will start with anomolay detection/removal using an Isolation Forest.\n",
    "\n",
    "iso_forest = IsolationForest(n_estimators=250,bootstrap=True).fit(X_train, y_train)\n",
    "\n",
    "outliers = iso_forest.predict(X_train)==-1\n",
    "X_train_iso = X_train[~outliers]\n",
    "y_train_iso = y_train[~outliers]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('scl', Normalizer(copy=True, norm='l2')), ('pca', PCA(copy=True, iterated_power='auto', n_components=10, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)), ('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we build the pipeline. We will scale the data using Normalizer() and reduce dimensions by feature extraction via \n",
    "# Principle Component Analysis. After experimentation, 10 components were determined to produce the best results.\n",
    "\n",
    "pipe_lr = Pipeline([('scl', Normalizer()),\n",
    "                    ('pca', PCA(n_components=10)),\n",
    "                    ('clf', LogisticRegression())])\n",
    "\n",
    "pipe_lr.fit(X_train_iso, y_train_iso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.82848392,  0.82055215,  0.83128834,  0.83128834,  0.84662577,\n",
       "        0.83128834,  0.83282209,  0.82334869,  0.85253456,  0.83717358])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_lr = cross_val_score(pipe_lr, X_test, y_test, cv=10)\n",
    "scores_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83354057866798625"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_lr.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        pred:0  pred:1\n",
      "true:0    2472     775\n",
      "true:1     326    2945\n"
     ]
    }
   ],
   "source": [
    "predictions_lr = pipe_lr.predict(X_test)\n",
    "\n",
    "unique_label = np.unique(y_test)\n",
    "print(pd.DataFrame(confusion_matrix(y_test, predictions_lr, labels=unique_label), \n",
    "                   index=['true:{:}'.format(x) for x in unique_label], \n",
    "                   columns=['pred:{:}'.format(x) for x in unique_label]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.76      0.82      3247\n",
      "          1       0.79      0.90      0.84      3271\n",
      "\n",
      "avg / total       0.84      0.83      0.83      6518\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predictions_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83108315434182267"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, predictions_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your 3rd pipeline\n",
    "  * Anomaly detection\n",
    "  * Dimensionality reduction\n",
    "  * Model training/validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add code below this comment  (Question #E8006)\n",
    "# ----------------------------------\n",
    "\n",
    "# For our third pipeline we will use a Random Forest model.\n",
    "# We will start with anomolay detection/removal using a One Class Support Vector Machine and utilize a Radial Basis Function\n",
    "# kernel.\n",
    "\n",
    "svm = OneClassSVM(kernel='rbf').fit(X_train, y_train)\n",
    "                                   \n",
    "svm_outliers = svm.predict(X_train)==-1\n",
    "X_train_svm = X_train[~svm_outliers]\n",
    "y_train_svm = y_train[~svm_outliers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('fa', FactorAnalysis(copy=True, iterated_power=3, max_iter=1000, n_components=10,\n",
       "        noise_variance_init=None, random_state=0, svd_method='randomized',\n",
       "        tol=0.01)), ('clf', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max...n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False))])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we build the pipeline. We will not scale the data because the Random Forest model relies on rules, and would not be\n",
    "# affected by any monotonic transformations of the variables. Dimension reduction will be executed via Factor Analysis.\n",
    "# After experimentation, 10 factors were determined to produce the best results.\n",
    "\n",
    "pipe_rf = Pipeline([('fa', FactorAnalysis(n_components=10)),\n",
    "                    ('clf', RandomForestClassifier())])\n",
    "\n",
    "pipe_rf.fit(X_train_svm, y_train_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.87136294,  0.86503067,  0.87883436,  0.85736196,  0.8696319 ,\n",
       "        0.89110429,  0.86042945,  0.88018433,  0.87250384,  0.85867896])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_rf = cross_val_score(pipe_rf, X_test, y_test, cv=10)\n",
    "scores_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87051227058086211"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_rf.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        pred:0  pred:1\n",
      "true:0    2010    1237\n",
      "true:1     165    3106\n"
     ]
    }
   ],
   "source": [
    "predictions_rf = pipe_rf.predict(X_test)\n",
    "\n",
    "unique_label = np.unique(y_test)\n",
    "print(pd.DataFrame(confusion_matrix(y_test, predictions_rf, labels=unique_label), \n",
    "                   index=['true:{:}'.format(x) for x in unique_label], \n",
    "                   columns=['pred:{:}'.format(x) for x in unique_label]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.62      0.74      3247\n",
      "          1       0.72      0.95      0.82      3271\n",
      "\n",
      "avg / total       0.82      0.78      0.78      6518\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predictions_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78490334458422828"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, predictions_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document the cross-validation analysis for the three models"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Write your analysis in this cell\n",
    "# (Question #E8007)\n",
    "# ----------------------------------\n",
    "\n",
    "The mean 10 fold cross validation score was roughly 51% for the Naive Bayes model, 83% for the Logistic Regression model, and 87% for the Random Forest. The Navie Bayes model can be immediately ruled out.\n",
    "\n",
    "The Random Forset did score better on the cross validation, however all other scores, including F1, were higher for the Logistic Regression model. The Random Forest did have more true positives, but the Logisitic Regression model had less false predictions overall. Because of this, the Logistic Regression model will be selected to proceed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"background:yellow\">Don't forget to share your chosen models and their cross-validation performance with the class on the dicussion board for module 8.</span>** \n",
    "\n",
    "---\n",
    "\n",
    "# Retrain a model using the full training data set\n",
    "\n",
    "## Train\n",
    "Use the full training data set to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1547519\n",
       "0    1547519\n",
       "Name: went_on_backorder, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add code below this comment  (Question #E8008)\n",
    "# ----------------------------------\n",
    "\n",
    "# We'll now train our chosen model on the entire training dataset. Remember, this is still training the model, so we still need\n",
    "# to account for the Yes/No imbalance in our target variable. This time let's upsample the data:\n",
    "\n",
    "dataset_minority_upsampled = resample(dataset_minority, \n",
    "                                replace=True,     # sample with replacement\n",
    "                                n_samples=(dataset_majority.went_on_backorder).count(),    # to match majority class\n",
    "                                random_state=456) # reproducible results\n",
    "\n",
    "# Combine minority class with upsampled majority class\n",
    "dataset_upsampled = pd.concat([dataset_minority_upsampled, dataset_majority])\n",
    "\n",
    "# Check that we did this right: show value counts\n",
    "dataset_upsampled.went_on_backorder.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# What follows is a sequence of splitting the upsampled training dataset into 4 subsets, which we then train our model on. In\n",
    "# this way we train our model on the entire training dataset without the kernel running out of memory. Each subset is ran\n",
    "# through an Isolation Forest to detect outliers, just as we did earlier with this model.\n",
    "\n",
    "one = np.random.rand(len(dataset_upsampled)) < .5\n",
    "a = dataset_upsampled[one]\n",
    "b = dataset_upsampled[~one]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "two = np.random.rand(len(a)) < .5\n",
    "c = a[two]\n",
    "d = a[~two]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "three = np.random.rand(len(b)) < .5\n",
    "e = b[three]\n",
    "f = b[~three]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X1 = c.iloc[:, :-1]\n",
    "y1 = c['went_on_backorder']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X2 = d.iloc[:, :-1]\n",
    "y2 = d['went_on_backorder']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X3 = e.iloc[:, :-1]\n",
    "y3 = e['went_on_backorder']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X4 = f.iloc[:, :-1]\n",
    "y4 = f['went_on_backorder']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('scl', Normalizer(copy=True, norm='l2')), ('pca', PCA(copy=True, iterated_power='auto', n_components=10, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)), ('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iso_forest = IsolationForest(n_estimators=250,bootstrap=True).fit(X1, y1)\n",
    "\n",
    "outliers = iso_forest.predict(X1)==-1\n",
    "X1_iso = X1[~outliers]\n",
    "y1_iso = y1[~outliers]\n",
    "\n",
    "pipe_lr.fit(X1_iso, y1_iso)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('scl', Normalizer(copy=True, norm='l2')), ('pca', PCA(copy=True, iterated_power='auto', n_components=10, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)), ('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iso_forest = IsolationForest(n_estimators=250,bootstrap=True).fit(X2, y2)\n",
    "\n",
    "outliers = iso_forest.predict(X2)==-1\n",
    "X2_iso = X2[~outliers]\n",
    "y2_iso = y2[~outliers]\n",
    "\n",
    "pipe_lr.fit(X2_iso, y2_iso)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('scl', Normalizer(copy=True, norm='l2')), ('pca', PCA(copy=True, iterated_power='auto', n_components=10, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)), ('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iso_forest = IsolationForest(n_estimators=250,bootstrap=True).fit(X3, y3)\n",
    "\n",
    "outliers = iso_forest.predict(X3)==-1\n",
    "X3_iso = X3[~outliers]\n",
    "y3_iso = y3[~outliers]\n",
    "\n",
    "pipe_lr.fit(X3_iso, y3_iso)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('scl', Normalizer(copy=True, norm='l2')), ('pca', PCA(copy=True, iterated_power='auto', n_components=10, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)), ('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iso_forest = IsolationForest(n_estimators=250,bootstrap=True).fit(X4, y4)\n",
    "\n",
    "outliers = iso_forest.predict(X4)==-1\n",
    "X4_iso = X4[~outliers]\n",
    "y4_iso = y4[~outliers]\n",
    "\n",
    "pipe_lr.fit(X4_iso, y4_iso)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the trained model with the pickle library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PipedLogReg.pkl']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add code below this comment  (Question #E8009)\n",
    "# ----------------------------------\n",
    "\n",
    "from sklearn.externals import joblib as jb\n",
    "\n",
    "jb.dump(pipe_lr, \"PipedLogReg.pkl\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reload the trained model from the pickle file\n",
    "### Load the Testing Data and evaluate your model\n",
    "\n",
    " * `/dsa/data/all_datasets/back_order/Kaggle_Test_Dataset_v2.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add code below this comment  (Question #E8010)\n",
    "# ----------------------------------\n",
    "\n",
    "from sklearn.externals import joblib as jb\n",
    "loaded_model = jb.load('PipedLogReg.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.4/site-packages/IPython/core/interactiveshell.py:2728: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# We will load the testing dataest and perform the same carpentry we performed on the training set pior to model fitting.\n",
    "\n",
    "TESTSET = '/dsa/data/all_datasets/back_order/Kaggle_Test_Dataset_v2.csv'\n",
    "assert os.path.exists(TESTSET)\n",
    "\n",
    "testset = pd.read_csv(TESTSET, na_values=na_other)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testset = testset.drop(['sku'], axis = 1)\n",
    "\n",
    "testset = testset.dropna()\n",
    "\n",
    "yes_no_columns = list(filter(lambda i: testset[i].dtype!=np.float64, testset.columns))\n",
    "for column_name in yes_no_columns:\n",
    "    testset[column_name] = testset[column_name].apply(['No', 'Yes'].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 222974 entries, 2 to 242074\n",
      "Data columns (total 22 columns):\n",
      "national_inv         222974 non-null float64\n",
      "lead_time            222974 non-null float64\n",
      "in_transit_qty       222974 non-null float64\n",
      "forecast_3_month     222974 non-null float64\n",
      "forecast_6_month     222974 non-null float64\n",
      "forecast_9_month     222974 non-null float64\n",
      "sales_1_month        222974 non-null float64\n",
      "sales_3_month        222974 non-null float64\n",
      "sales_6_month        222974 non-null float64\n",
      "sales_9_month        222974 non-null float64\n",
      "min_bank             222974 non-null float64\n",
      "potential_issue      222974 non-null int64\n",
      "pieces_past_due      222974 non-null float64\n",
      "perf_6_month_avg     222974 non-null float64\n",
      "perf_12_month_avg    222974 non-null float64\n",
      "local_bo_qty         222974 non-null float64\n",
      "deck_risk            222974 non-null int64\n",
      "oe_constraint        222974 non-null int64\n",
      "ppap_risk            222974 non-null int64\n",
      "stop_auto_buy        222974 non-null int64\n",
      "rev_stop             222974 non-null int64\n",
      "went_on_backorder    222974 non-null int64\n",
      "dtypes: float64(15), int64(7)\n",
      "memory usage: 39.1 MB\n"
     ]
    }
   ],
   "source": [
    "testset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset.isnull().any().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testset = testset.sample(frac = 1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = testset.iloc[:, :-1]\n",
    "y = testset['went_on_backorder']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test\n",
    "\n",
    "Test your new model using the testing data set.\n",
    " * `/dsa/data/all_datasets/back_order/Kaggle_Test_Dataset_v2.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        pred:0  pred:1\n",
      "true:0  169829   50581\n",
      "true:1     330    2234\n"
     ]
    }
   ],
   "source": [
    "# Add code below this comment  (Question #E8011)\n",
    "# ----------------------------------\n",
    "\n",
    "loaded_model_predictions = loaded_model.predict(X)\n",
    "\n",
    "unique_label = np.unique(y)\n",
    "print(pd.DataFrame(confusion_matrix(y, loaded_model_predictions, labels=unique_label), \n",
    "                   index=['true:{:}'.format(x) for x in unique_label], \n",
    "                   columns=['pred:{:}'.format(x) for x in unique_label]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.77      0.87    220410\n",
      "          1       0.04      0.87      0.08      2564\n",
      "\n",
      "avg / total       0.99      0.77      0.86    222974\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y, loaded_model_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.771672930476199"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y, loaded_model_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Write a summary of your processing and an analysis of the model performance  \n",
    "# (Question #E8012)\n",
    "# ----------------------------------\n",
    "\n",
    "Three models were developed, each based on methods that were expected to work best together in order to provide the best results.\n",
    "\n",
    "The Logisitic Regression model was elected as the model to utilize due to its high accuracy. Accuracy was only able to be a deciding factor because the imbalanced target values were recognized and accounted for via up and down sampling of the training data.\n",
    "\n",
    "When presented with the testing dataset, the trainied Logistic Regression Model performed well with an F1 score of 0.86. It predicted 77% of the \"No\" values correctly, and 87% of the \"Yes\" values correctly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflect\n",
    "\n",
    "Imagine you are data scientist that has been tasked with developing a system to save your \n",
    "company money by predicting and preventing back orders of parts in the supply chain.\n",
    "\n",
    "Write a **brief summary** for \"management\" that details your findings, \n",
    "your level of certainty and trust in the models, \n",
    "and recommendations for operationalizing these models for the business."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Write your answer here:  \n",
    "# (Question #E8013)\n",
    "# ----------------------------------\n",
    "\n",
    "Review of the data resulted in the development and testing of three classifier (predictive) models. Of those three one was determined to out perform the others in prediciting whether or not a product would go on backorder. \n",
    "\n",
    "Based on the historical data we used for training and testing, this model ws able to predict 77% of the products that did not go on backorder correctly, and it was able to predict 87% of the products that did go on backorder correctly. The model's F1 score, which is a weighted measure of accuracy, was 86%. The weightedness takes into consideration the imbalance of the data (i.e., products are less likely to go on backorder in general, so this is accounted for in the metric). The model's F1 score actually improved when presented with new data it had never seen before, compared to the data it was originally trained on.\n",
    "\n",
    "It should be further noted that, within the realm of the model's inaccuracy, it is more likely to incorrectly predict a product will go on backorder rather than incorrectly predict a product will not go on backorder. It should thus be taken into consideration which is more costly, a product not going on backorder that is expected to, or a product going on backorder that is not expected to.\n",
    "\n",
    "Given the results of this model's testing, I can confidentally say that it will peform similarly to the results presented if it is maintained and retrained on new data, and if no drastic deviation in observation features occur. The model is not resource intensive for the results that it provides, and so its imprint on dedicatable resources should be minimal.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save your notebook!\n",
    "## The `File > Close and Halt`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
